{% extends "base.html" %}

{% block title %}Model Comparison - FraudGuard AI{% endblock %}

{% block content %}
<div class="container-fluid mt-4">
    <div class="row">
        <div class="col-12">
            <div class="card border-0 shadow">
                <div class="card-header bg-info text-white">
                    <h4 class="mb-0"><i class="fas fa-balance-scale"></i> Model Comparison Analysis</h4>
                    <small>Side-by-side comparison of all fraud detection models</small>
                </div>
                <div class="card-body">
                    {% if models and metrics %}
                        <!-- Model Selection for Comparison -->
                        <div class="row mb-4">
                            <div class="col-md-6">
                                <label class="form-label fw-bold">Select Models to Compare:</label>
                                <div class="model-checkboxes">
                                    {% for model in models %}
                                        <div class="form-check form-check-inline">
                                            <input class="form-check-input model-checkbox" type="checkbox" 
                                                   id="model_{{ model }}" value="{{ model }}" checked>
                                            <label class="form-check-label" for="model_{{ model }}">
                                                {{ model.replace('_', ' ').title() }}
                                            </label>
                                        </div>
                                    {% endfor %}
                                </div>
                            </div>
                            <div class="col-md-6">
                                <label class="form-label fw-bold">Comparison Metrics:</label>
                                <select class="form-select" id="comparisonMetric">
                                    <option value="roc_auc">ROC AUC Score</option>
                                    <option value="precision">Precision</option>
                                    <option value="recall">Recall</option>
                                    <option value="f1_score">F1 Score</option>
                                    <option value="accuracy">Accuracy</option>
                                </select>
                            </div>
                        </div>

                        <!-- Side-by-Side Comparison -->
                        <div class="row" id="comparisonCards">
                            {% for model_name, model_metrics in metrics.items() %}
                                <div class="col-lg-4 col-md-6 mb-4">
                                    <div class="card h-100 border-primary">
                                        <div class="card-header bg-primary text-white">
                                            <h6 class="mb-0">{{ model_name.replace('_', ' ').title() }}</h6>
                                        </div>
                                        <div class="card-body">
                                            {% if model_metrics.get('error') %}
                                                <div class="alert alert-warning">
                                                    <small>{{ model_metrics.error }}</small>
                                                </div>
                                            {% else %}
                                                <div class="row text-center">
                                                    <div class="col-6 mb-2">
                                                        <strong>ROC AUC</strong><br>
                                                        <span class="text-primary">{{ "%.4f"|format(model_metrics.get('roc_auc_score', 0)) }}</span>
                                                    </div>
                                                    <div class="col-6 mb-2">
                                                        <strong>Precision</strong><br>
                                                        <span class="text-success">{{ "%.4f"|format(model_metrics.get('classification_report', {}).get('1', {}).get('precision', 0)) }}</span>
                                                    </div>
                                                    <div class="col-6 mb-2">
                                                        <strong>Recall</strong><br>
                                                        <span class="text-warning">{{ "%.4f"|format(model_metrics.get('classification_report', {}).get('1', {}).get('recall', 0)) }}</span>
                                                    </div>
                                                    <div class="col-6 mb-2">
                                                        <strong>F1 Score</strong><br>
                                                        <span class="text-info">{{ "%.4f"|format(model_metrics.get('classification_report', {}).get('1', {}).get('f1-score', 0)) }}</span>
                                                    </div>
                                                </div>
                                            {% endif %}
                                        </div>
                                    </div>
                                </div>
                            {% endfor %}
                        </div>

                        <!-- Comparison Charts -->
                        <div class="row mt-4">
                            <div class="col-lg-8">
                                <div class="card">
                                    <div class="card-header">
                                        <h6 class="mb-0">Performance Comparison</h6>
                                    </div>
                                    <div class="card-body">
                                        <canvas id="comparisonChart"></canvas>
                                    </div>
                                </div>
                            </div>
                            <div class="col-lg-4">
                                <div class="card">
                                    <div class="card-header">
                                        <h6 class="mb-0">Best Model Ranking</h6>
                                    </div>
                                    <div class="card-body">
                                        <div id="rankingList">
                                            {% set sorted_models = metrics.items() | list %}
                                            {% for model_name, model_metrics in sorted_models %}
                                                <div class="d-flex justify-content-between align-items-center mb-2">
                                                    <span>{{ loop.index }}. {{ model_name.replace('_', ' ').title() }}</span>
                                                    <span class="badge bg-primary">{{ "%.3f"|format(model_metrics.get('roc_auc_score', 0)) }}</span>
                                                </div>
                                            {% endfor %}
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <!-- Detailed Comparison Table -->
                        <div class="row mt-4">
                            <div class="col-12">
                                <div class="card">
                                    <div class="card-header">
                                        <h6 class="mb-0">Detailed Comparison</h6>
                                    </div>
                                    <div class="card-body">
                                        <div class="table-responsive">
                                            <table class="table table-striped table-hover">
                                                <thead class="table-dark">
                                                    <tr>
                                                        <th>Model</th>
                                                        <th>ROC AUC</th>
                                                        <th>Precision</th>
                                                        <th>Recall</th>
                                                        <th>F1 Score</th>
                                                        <th>Accuracy</th>
                                                        <th>Status</th>
                                                    </tr>
                                                </thead>
                                                <tbody>
                                                    {% for model_name, model_metrics in metrics.items() %}
                                                        <tr>
                                                            <td><strong>{{ model_name.replace('_', ' ').title() }}</strong></td>
                                                            <td>{{ "%.4f"|format(model_metrics.get('roc_auc_score', 0)) }}</td>
                                                            <td>{{ "%.4f"|format(model_metrics.get('classification_report', {}).get('1', {}).get('precision', 0)) }}</td>
                                                            <td>{{ "%.4f"|format(model_metrics.get('classification_report', {}).get('1', {}).get('recall', 0)) }}</td>
                                                            <td>{{ "%.4f"|format(model_metrics.get('classification_report', {}).get('1', {}).get('f1-score', 0)) }}</td>
                                                            <td>{{ "%.4f"|format(model_metrics.get('classification_report', {}).get('accuracy', 0)) }}</td>
                                                            <td>
                                                                {% if model_metrics.get('error') %}
                                                                    <span class="badge bg-danger">Error</span>
                                                                {% else %}
                                                                    <span class="badge bg-success">Active</span>
                                                                {% endif %}
                                                            </td>
                                                        </tr>
                                                    {% endfor %}
                                                </tbody>
                                            </table>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <!-- Recommendations -->
                        <div class="row mt-4">
                            <div class="col-12">
                                <div class="card border-success">
                                    <div class="card-header bg-success text-white">
                                        <h6 class="mb-0"><i class="fas fa-lightbulb"></i> Recommendations</h6>
                                    </div>
                                    <div class="card-body">
                                        <div id="recommendations">
                                            {% if metrics %}
                                                {% set best_model = metrics.items() | selectattr('1.roc_auc_score') | list | sort(attribute='1.roc_auc_score', reverse=true) | first %}
                                                {% if best_model %}
                                                    <div class="alert alert-success">
                                                        <h6><i class="fas fa-trophy"></i> Best Performing Model</h6>
                                                        <p><strong>{{ best_model[0].replace('_', ' ').title() }}</strong> shows the best overall performance with an ROC AUC of {{ "%.4f"|format(best_model[1].get('roc_auc_score', 0)) }}.</p>
                                                        <p>This model provides the best balance between fraud detection and false positive rates.</p>
                                                    </div>
                                                {% endif %}
                                                
                                                <div class="alert alert-info">
                                                    <h6><i class="fas fa-info-circle"></i> Usage Recommendations</h6>
                                                    <ul class="mb-0">
                                                        <li><strong>High Precision:</strong> Use for automated blocking of transactions</li>
                                                        <li><strong>High Recall:</strong> Use for fraud investigation workflows</li>
                                                        <li><strong>Balanced F1:</strong> Use for general fraud detection systems</li>
                                                        <li><strong>Ensemble:</strong> Combine multiple models for best results</li>
                                                    </ul>
                                                </div>
                                            {% endif %}
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    {% else %}
                        <!-- No models or metrics available -->
                        <div class="row">
                            <div class="col-12">
                                <div class="alert alert-warning text-center">
                                    <h5><i class="fas fa-exclamation-triangle"></i> No Models Available for Comparison</h5>
                                    <p>No trained models found. Please train some models first before accessing the comparison page.</p>
                                    <a href="{{ url_for('main.index') }}" class="btn btn-primary">
                                        <i class="fas fa-home"></i> Go to Home
                                    </a>
                                    <a href="#" onclick="window.history.back()" class="btn btn-secondary">
                                        <i class="fas fa-arrow-left"></i> Go Back
                                    </a>
                                </div>
                            </div>
                        </div>
                    {% endif %}
                </div>
            </div>
        </div>
    </div>
</div>
{% endblock %}

{% block scripts %}
{% if models and metrics %}
<script src="{{ url_for('static', filename='js/comparison.js') }}"></script>
<script>
// Make data available globally
window.availableModels = {{ models | tojson }};
window.modelMetrics = {{ metrics | tojson }};

console.log('Available models:', window.availableModels);
console.log('Model metrics:', window.modelMetrics);

document.addEventListener('DOMContentLoaded', function() {
    try {
        if (typeof initializeComparison === 'function') {
            initializeComparison();
        } else {
            console.warn('initializeComparison function not found');
        }
    } catch (error) {
        console.error('Error initializing comparison:', error);
    }
});
</script>
{% else %}
<script>
console.warn('No models or metrics data available for comparison');
</script>
{% endif %}
{% endblock %}